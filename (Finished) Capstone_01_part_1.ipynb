{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2379e98",
   "metadata": {},
   "source": [
    "The code cell provided below is for the reference code to unzip the unput dataset on your local system.\n",
    "\n",
    "#### Note: We do not recommend running the code in the lab environment. The zip file size will delay the code execution and may lead to some unforseen errors. The input files have already been unzipped for use in this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.unpack_archive(\"Images.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99733684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of available devices\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# # Disable GPU\n",
    "# if gpus:\n",
    "#     tf.config.set_visible_devices([], \"GPU\")\n",
    "#     print(\"GPU disabled. Running on CPU.\")\n",
    "\n",
    "# Enable GPU\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "    print(\"GPU enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa21229",
   "metadata": {},
   "source": [
    "#### Step 1: Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70411b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas,os,cv2 and numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95570e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 2: Load and preprocess the data\n",
    "\n",
    "# Load the labels from labels.csv\n",
    "# // TODO\n",
    "\n",
    "labels_df = pd.read_csv(\"./labels.csv\")\n",
    "\n",
    "labels_df.columns = [\"image_id\", \"class\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
    "\n",
    "# Adjust the image IDs in the dataframe\n",
    "labels_df[\"image_id\"] = labels_df[\"image_id\"].apply(lambda x: f\"{x:08d}\")\n",
    "\n",
    "# Use iloc to pick the first 1000 labels\n",
    "# // TODO\n",
    "labels_df = labels_df.iloc[:1000]\n",
    "\n",
    "\n",
    "# Load the corresponding images\n",
    "images_dir = \"Images/\"\n",
    "images = []\n",
    "for index, row in tqdm(labels_df.iterrows(), total=labels_df.shape[0]):\n",
    "    img_path = os.path.join(images_dir, f\"{row['image_id']}.jpg\")\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        images.append(img)\n",
    "    else:\n",
    "        print(f\"Error loading image: {img_path}\")\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "# Check if images are loaded\n",
    "# // TODO\n",
    "print(f\"\\nNum of Images: {images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ae0fb",
   "metadata": {},
   "source": [
    "#### Step 2: Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645102d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of vehicle types in the limited dataset\n",
    "# // TODO\n",
    "labels_df[\"class\"].value_counts()\n",
    "\n",
    "# Address data quality issues arising from the discrepancy between labels and actual image filenames\n",
    "# Sorting the image filenames\n",
    "# // TODO\n",
    "# @ I believe that all of the labels and image file names are correct. I also believe that all of the image file names are sorted.\n",
    "# @ So if there's something I should do here, please let me know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139159cf",
   "metadata": {},
   "source": [
    "#### Step 3: Preprocess the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the 'images' list is not empty\n",
    "if len(images) > 0:\n",
    "    # // TODO\n",
    "    resized_imgs = []\n",
    "    for img in images:\n",
    "        # Resize each image in the 'images' list to dimensions 224x224\n",
    "        resized_imgs.append(cv2.resize(img, (224, 224)))\n",
    "\n",
    "    # Convert the list of resized images to a NumPy array\n",
    "    processed_images = np.array(resized_imgs)\n",
    "\n",
    "    # Print a success message indicating that the images were resized successfully\n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af923407",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c60726",
   "metadata": {},
   "source": [
    "#### Step4: Prepare the labels and bounding boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_df[\"class\"].to_numpy()\n",
    "bounding_boxes = labels_df[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].to_numpy()\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "unique_labels = np.unique(labels)\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "index_to_label = {index: label for index, label in enumerate(unique_labels)}\n",
    "labels = np.array([label_to_index[label] for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ec6c5",
   "metadata": {},
   "source": [
    "#### Step5: Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bc0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // TODO\n",
    "# Split the data into training and testing sets using the train_test_split function.\n",
    "# - `processed_images`: The input images that have been resized and preprocessed.\n",
    "# - `labels`: The corresponding labels for the images.\n",
    "# - `bounding_boxes`: Bounding box information for the images.\n",
    "# - `test_size=0.2`: Specifies that 20% of the data will be used for testing, while 80% will be used for training.\n",
    "# - `random_state=42`: Sets a random seed for reproducibility.\n",
    "x_train, x_test, y_train, y_test, bbox_train, bbox_test = train_test_split(\n",
    "    processed_images,\n",
    "    labels,\n",
    "    bounding_boxes,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d90f9",
   "metadata": {},
   "source": [
    "#### Step6: Model Creation and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6213704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    vehicle_class = layers.Dense(\n",
    "        num_classes, activation=\"softmax\", name=\"vehicle_class\"\n",
    "    )(x)\n",
    "    bounding_box = layers.Dense(4, name=\"bounding_box\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=[vehicle_class, bounding_box])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = processed_images[0].shape\n",
    "print(f\"input_shape: {input_shape}\")\n",
    "num_classes = len(unique_labels)\n",
    "print(f\"num_classes: {num_classes}\")\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"vehicle_class\": \"sparse_categorical_crossentropy\", \"bounding_box\": \"mse\"},\n",
    "    metrics={\"vehicle_class\": \"accuracy\", \"bounding_box\": \"mae\"},\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    {\"vehicle_class\": y_train, \"bounding_box\": bbox_train},\n",
    "    epochs=25,\n",
    "    validation_data=(x_test, {\"vehicle_class\": y_test, \"bounding_box\": bbox_test}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447def3f",
   "metadata": {},
   "source": [
    "#### Step7: Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the test data.\n",
    "# // TODO\n",
    "results = model.evaluate(x_test, {\"vehicle_class\": y_test, \"bounding_box\": bbox_test})\n",
    "# The 'model.evaluate' function calculates various metrics and loss values.\n",
    "# It takes the test data 'x_test' as input and a dictionary that specifies the\n",
    "# expected outputs for two different tasks: 'vehicle_class' and 'bounding_box'.\n",
    "\n",
    "# Print the test results to the console.\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9268a",
   "metadata": {},
   "source": [
    "#### Step8: Inferencing and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e934f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a few sample images for inference\n",
    "# // TODO  (Adjust the number of sample images as needed)\n",
    "sample_images = x_train[0:1]\n",
    "\n",
    "# Perform inference on the sample images\n",
    "# // TODO\n",
    "predictions = model.predict(sample_images)\n",
    "print(f\"predictions: {predictions[1]}\")\n",
    "\n",
    "# Extract the predicted bounding box coordinates\n",
    "# // TODO\n",
    "predicted_bounding_boxes = predictions[1]\n",
    "\n",
    "# Visualize the sample images with predicted bounding boxes\n",
    "for i in range(len(sample_images)):\n",
    "    plt.figure()\n",
    "    plt.imshow(sample_images[i])\n",
    "\n",
    "    # The red square is where the model guessed where the vehicle is\n",
    "    plt.gca().add_patch(\n",
    "        plt.Rectangle(\n",
    "            (predicted_bounding_boxes[i][0], predicted_bounding_boxes[i][1]),\n",
    "            predicted_bounding_boxes[i][2] - predicted_bounding_boxes[i][0],\n",
    "            predicted_bounding_boxes[i][3] - predicted_bounding_boxes[i][1],\n",
    "            fill=False,\n",
    "            edgecolor=\"r\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "    )\n",
    "    # The green square is where the vehicle actually is.\n",
    "    # (In this case, the Bounding Boxes are wrong because we do not scale the bounding boxes as we do with the images)\n",
    "    plt.gca().add_patch(\n",
    "        plt.Rectangle(\n",
    "            (bbox_train[i][0], bbox_train[i][1]),\n",
    "            bbox_train[i][2] - bbox_train[i][0],\n",
    "            bbox_train[i][3] - bbox_train[i][1],\n",
    "            fill=False,\n",
    "            edgecolor=\"g\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884197c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
